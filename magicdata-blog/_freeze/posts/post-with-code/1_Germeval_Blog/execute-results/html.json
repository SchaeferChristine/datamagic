{
  "hash": "126e2e5dd4195430213083f73cdaa82f",
  "result": {
    "markdown": "---\ntitle: \"1_Germeval2018\"\nformat: html\neditor: visual\n---\n\n\n# Vorbereitung\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(tidymodels)\nlibrary(tidytext)  # Textmining\nlibrary(textrecipes)  # Textanalysen in Tidymodels-Rezepten\nlibrary(lsa)  # stopwords\nlibrary(discrim)  # naive bayes classification\nlibrary(naivebayes)\nlibrary(tictoc)  # Zeitmessung\nlibrary(fastrtext)  # Worteinbettungen\nlibrary(remoji)  # Emojis\nlibrary(tokenizers)  # Vektoren tokenisieren\nlibrary(syuzhet)\nlibrary(pradadata)\nlibrary(doParallel)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(wc.cores = parallel::detectCores())\n```\n:::\n\n\n## Datensätze\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"germeval_train\") \n\ndata(\"germeval_test\")\n\ndata(\"sentiws\")\n\ndata(\"schimpfwoerter\")\n\ndata(\"wild_emojis\", package = \"pradadata\")\n\nd_train <- germeval_train\nd_test <- germeval_test\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(d_train) <- c(\"id\", \"text\", \"c1\", \"c2\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwiki_de_embeds_path <- \"/Users/chrissi/Dokumente/Angewandte Wirtschafts- und Medienpsychologie/WS 2023:24/Data Science 2/Wiki2Vec_German.txt\"\n\nwiki_de_embeds <-\n  data.table::fread(file = wiki_de_embeds_path,\n                    sep = \" \",\n                    header = FALSE,\n                    showProgress = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(wiki_de_embeds)[1] <- \"word\"\n\nwiki <- as_tibble(wiki_de_embeds)\n```\n:::\n\n\n# Textanalyse\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train %>% \n  count(c1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       c1    n\n1 OFFENSE 1688\n2   OTHER 3321\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train %>% \n  count(c2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         c2    n\n1     ABUSE 1022\n2    INSULT  595\n3     OTHER 3321\n4 PROFANITY   71\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain2 <-\n  d_train %>% \n  mutate(text_length = str_length(text))\n```\n:::\n\n\nDurchschnittliche Textlänge:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain2 %>% \n  summarise(mean(text_length)) %>% round(0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  mean(text_length)\n1               142\n```\n:::\n:::\n\n\n## Sentimentanalyse vorab\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nsenti1 <- get_nrc_sentiment(d_train$text, language = \"german\")\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n144.196 sec elapsed\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsenti1 %>% \n  summarise(across(.cols = everything(), .fns = sum))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  anger anticipation disgust fear joy sadness surprise trust negative positive\n1   399          567     306  499 384     730      265   840     1449     1753\n```\n:::\n:::\n\n\nAnteil der negativen Gefühle:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsenti1 %>% \n  summarise(anger_prop = 399/1449,\n            disgust_prop = 306/1449,\n            fear_prop = 499/1449,\n            sadness_prop = 730/1449)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  anger_prop disgust_prop fear_prop sadness_prop\n1  0.2753623    0.2111801 0.3443754    0.5037957\n```\n:::\n:::\n\n\nAnteile positive Gefühle:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsenti1 %>% \n  summarise(anticipation_prop = 567/1753,\n            joy_prop = 384/1753,\n            surprise_prop = 265/1753,\n            trust_prop = 840/1753)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  anticipation_prop  joy_prop surprise_prop trust_prop\n1         0.3234455 0.2190531     0.1511694  0.4791786\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nsenti2 <- get_sentiment(d_train$text,\n              method = \"custom\",\n              lexicon = sentiws) %>% \n  as_tibble()\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n11.178 sec elapsed\n```\n:::\n:::\n\n\n## Schimpfwörter\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_long <- \n  d_train %>% \n  unnest_tokens(input = text, output = token)\n\nd_schimpf <- \n  train_long %>% \n  select(id, token) %>% \n  mutate(schimpf = token %in% schimpfwoerter$word)\n\nd_schimpf %>% \n  count(schimpf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  schimpf     n\n1   FALSE 99105\n2    TRUE  1112\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain3 <-\n  train_long %>% \n  full_join(d_schimpf,relationship = \"many-to-many\") %>% \n  select(-c1, -c2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(id, token)`\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain3 %>% \n  dplyr::filter(schimpf == \"TRUE\") %>% \n  nrow()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1168\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nschimpfwoerter <- \n  schimpfwoerter %>% \n  mutate(value = 1)\n```\n:::\n\n\n## Emojis\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_emojis <- \n  train2 %>% \n  select(id, text) %>% \n  mutate(wild_emoji = text %in% wild_emojis$emoji)\n\n\nd_emojis %>% \n  filter(wild_emoji == \"TRUE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] id         text       wild_emoji\n<0 rows> (or 0-length row.names)\n```\n:::\n:::\n\n\nScheinbar keine Hass-Emojis\n\n# Tidymodels\n\n## Kreuzvalidierung\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nfolds1 <- vfold_cv(train2, v = 5)\n```\n:::\n\n\n## Rezept\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec1 <- \n  recipe(c1 ~ ., data = train2) %>% \n  update_role(id, new_role = \"id\")  %>% \n  update_role(c2, new_role = \"ignore\") %>% \n  step_mutate(n_schimpf = get_sentiment(text, method = \"custom\", lexicon = schimpfwoerter)) %>% \n  step_mutate(rsenti = get_sentiment(text, method = \"custom\", lexicon = sentiws)) %>% \n  step_tokenize(text) %>%\n  step_stopwords(text, keep = FALSE, language = \"de\") %>%\n  step_word_embeddings(text,\n                       embeddings = wiki,\n                       aggregation = \"mean\") %>% \n  step_zv() %>% \n  step_normalize(all_numeric_predictors())\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrec1_prep <- prep(rec1, train2)\n\nrec1_bake <- bake(rec1_prep, new_data = NULL)\n\nhead(rec1_bake)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 106\n     id c2     text_length c1      n_schimpf  rsenti wordembed_text_V2\n  <int> <fct>        <dbl> <fct>       <dbl>   <dbl>             <dbl>\n1     1 OTHER     -0.452   OTHER      -0.450  0.0613             0.557\n2     2 OTHER     -0.00378 OTHER      -0.450 -1.73              -0.552\n3     3 OTHER     -0.996   OTHER      -0.450  0.0409            -0.850\n4     4 OTHER     -0.0310  OTHER      -0.450  0.0409             0.953\n5     5 INSULT    -0.0853  OFFENSE    -0.450  0.0409             0.436\n6     6 OTHER      1.93    OTHER      -0.450 -1.73              -0.453\n# ℹ 99 more variables: wordembed_text_V3 <dbl>, wordembed_text_V4 <dbl>,\n#   wordembed_text_V5 <dbl>, wordembed_text_V6 <dbl>, wordembed_text_V7 <dbl>,\n#   wordembed_text_V8 <dbl>, wordembed_text_V9 <dbl>, wordembed_text_V10 <dbl>,\n#   wordembed_text_V11 <dbl>, wordembed_text_V12 <dbl>,\n#   wordembed_text_V13 <dbl>, wordembed_text_V14 <dbl>,\n#   wordembed_text_V15 <dbl>, wordembed_text_V16 <dbl>,\n#   wordembed_text_V17 <dbl>, wordembed_text_V18 <dbl>, …\n```\n:::\n:::\n\n\n## Naive Bayes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_modell <- naive_Bayes() %>%\n  set_mode(\"classification\") %>%\n  set_engine(\"naivebayes\")\n\nwf1 <-\n  workflow() %>% \n  add_recipe(rec1) %>% \n  add_model(nb_modell)\n\ntic()\nfit1 <-\n  fit_resamples(\n    wf1,\n    folds1,\n    control = control_resamples(save_pred = TRUE)\n  )\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n226.292 sec elapsed\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwf1_performance <-\n  collect_metrics(fit1)\n\nwf1_performance\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.687     5 0.00199 Preprocessor1_Model1\n2 roc_auc  binary     0.730     5 0.00427 Preprocessor1_Model1\n```\n:::\n:::\n\n\n## Logistische Regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlasso_modell <- logistic_reg(penalty = tune(), mixture = 1) %>%\n  set_mode(\"classification\") %>%\n  set_engine(\"glmnet\")\n\nwf2 <- workflow() %>% \n  add_recipe(rec1) %>% \n  add_model(lasso_modell)\n\nlambda_grid <- grid_regular(penalty(), levels = 5)  \n\ntic()\nfit2 <- \n  tune_grid(wf2, folds1, grid = lambda_grid, control = control_resamples(save_pred = TRUE))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n259.561 sec elapsed\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwf2_performance <- collect_metrics(fit2)\n\nwf2_performance\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 7\n        penalty .metric  .estimator  mean     n std_err .config             \n          <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n 1 0.0000000001 accuracy binary     0.723     5 0.00552 Preprocessor1_Model1\n 2 0.0000000001 roc_auc  binary     0.767     5 0.00909 Preprocessor1_Model1\n 3 0.0000000316 accuracy binary     0.723     5 0.00552 Preprocessor1_Model2\n 4 0.0000000316 roc_auc  binary     0.767     5 0.00909 Preprocessor1_Model2\n 5 0.00001      accuracy binary     0.723     5 0.00552 Preprocessor1_Model3\n 6 0.00001      roc_auc  binary     0.767     5 0.00909 Preprocessor1_Model3\n 7 0.00316      accuracy binary     0.719     5 0.00501 Preprocessor1_Model4\n 8 0.00316      roc_auc  binary     0.767     5 0.00939 Preprocessor1_Model4\n 9 1            accuracy binary     0.663     5 0.00552 Preprocessor1_Model5\n10 1            roc_auc  binary     0.5       5 0       Preprocessor1_Model5\n```\n:::\n:::\n\n\n## Random Forest\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_model <- \n  rand_forest(mtry = 3,\n              min_n = tune(),\n              trees = 1000) %>% \n  set_engine(\"ranger\") %>% \n  set_mode(\"classification\")\n\nrf_wf <- \n  workflow() %>% \n  add_model(rf_model) %>% \n  add_recipe(rec1)\n\nrf_grid <- \n  grid_regular(min_n(), levels = 4)\n\ntic()\nrf_fit <- \n  tune_grid(object = rf_wf, resamples = folds1, grid = rf_grid)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n649.555 sec elapsed\n```\n:::\n\n```{.r .cell-code}\nshow_best(rf_fit)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: No value of `metric` was given; metric 'roc_auc' will be used.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 7\n  min_n .metric .estimator  mean     n std_err .config             \n  <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1     2 roc_auc binary     0.784     5 0.00584 Preprocessor1_Model1\n2    27 roc_auc binary     0.781     5 0.00565 Preprocessor1_Model3\n3    40 roc_auc binary     0.780     5 0.00650 Preprocessor1_Model4\n4    14 roc_auc binary     0.780     5 0.00685 Preprocessor1_Model2\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_final_wf <- \n  rf_wf %>% \n  finalize_workflow(select_best(rf_fit))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: No value of `metric` was given; metric 'roc_auc' will be used.\n```\n:::\n:::\n\n\n# Fitten und Vorhersagen\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_train <- \n  rf_final_wf %>% \n  fit(train2)\n```\n:::\n\n\n## Vorbereitung Test-Datensatz\n\nTextlänge\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest2 <-\n  d_test %>% \n  mutate(text_length = str_length(text))\n```\n:::\n\n\nSentimentanalyse\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsenti_test <- get_sentiment(d_test$text,\n              method = \"custom\",\n              lexicon = sentiws) %>% \n  as_tibble()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest3 <- test2 %>% \n  bind_cols(value = senti_test$value) %>% \n  mutate(id = row_number())\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_test <- \n  fit_train %>% \n  predict(test3)\n```\n:::\n\n\n# Güte überprüfen\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest4 <-\n  test3 |> \n  bind_cols(fit_test) |> \n  mutate(c1 = as.factor(c1))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_metrics <- metric_set(accuracy, f_meas)\nmy_metrics(test4,\n           truth = c1,\n           estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.699\n2 f_meas   binary         0.259\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}